{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "# Copyright 2014-2021 Intel Corporation\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#==============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# daal4py Gradient Boosting Classification model creation from XGBoost example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will train a XGBoost model and predict using the daal4py prediction method for increased performance. Intel optimized XGBoost and daal4py shipped as a part of the oneAPI AI Analytics Toolkit.\n",
    "\n",
    "In this example, we will use a dataset with particle features and functions of those features **to distinguish between a signal process which produces Higgs bosons (1) and a background process which does not (0)**. The Higgs boson is a basic particle in the standard model produced by the quantum excitation of the Higgs field, named after physicist Peter Higgs. Users can opt to remove the data portion of this sample and replace it with their own data as they see fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Organizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by **importing** all necessary data and packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daal4py as d4p\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's **load** in the Higgs dataset and **organize** it as necessary to work with our model. You can opt to remove this cell and add your own data as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_higgs(nrows_train, nrows_test, dtype=np.float32):\n",
    "    if not os.path.isfile(\"./data/batch/HIGGS.csv.gz\"):\n",
    "        print(\"Loading data set...\")\n",
    "        url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\"\n",
    "        myfile = requests.get(url)\n",
    "        open('./data/batch/HIGGS.csv.gz', 'wb').write(myfile.content)\n",
    "    print(\"Reading data set...\")\n",
    "    data = pd.read_csv(\"./data/batch/HIGGS.csv.gz\", delimiter=\",\", header=None, compression=\"gzip\", dtype=dtype, nrows=nrows_train+nrows_test)\n",
    "    print(\"Pre-processing data set...\")\n",
    "    data = data[list(data.columns[1:])+list(data.columns[0:1])]\n",
    "    n_features = data.shape[1]-1\n",
    "    train_data = np.ascontiguousarray(data.values[:nrows_train,:n_features])\n",
    "    train_label = np.ascontiguousarray(data.values[:nrows_train,n_features])\n",
    "    test_data = np.ascontiguousarray(data.values[nrows_train:nrows_train+nrows_test,:n_features])\n",
    "    test_label = np.ascontiguousarray(data.values[nrows_train:nrows_train+nrows_test,n_features])\n",
    "    n_classes = len(np.unique(train_label))\n",
    "    print(sys.getsizeof(train_data))\n",
    "    return train_data, train_label, test_data, test_label, n_classes, n_features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run this model and prediction using 100,000 rows of the Higgs dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label, test_data, test_label, n_classes, n_features = load_higgs(100000, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting and training the model** using the training dataset, which consists of particle features and functions of those features to help discern between a signal process that produces Higgs bosons and background process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set XGBoost parameters\n",
    "xgb_params = {\n",
    "    'verbosity':                    0,\n",
    "    'alpha':                        0.9,\n",
    "    'max_bin':                      256,\n",
    "    'scale_pos_weight':             2,\n",
    "    'learning_rate':                0.1,\n",
    "    'subsample':                    1,\n",
    "    'reg_lambda':                   1,\n",
    "    \"min_child_weight\":             0,\n",
    "    'max_depth':                    8,\n",
    "    'max_leaves':                   2**8,\n",
    "    'objective':                    'binary:logistic',\n",
    "    'predictor':                    'cpu_predictor',\n",
    "    'tree_method':                  'hist',\n",
    "    'n_estimators':                1000\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "t0 = time.time() #begin timer\n",
    "model_xgb= xgb.XGBClassifier(**xgb_params)\n",
    "model_xgb.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using daal4py for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also make a prediction using XGBoost for accuracy/performance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost prediction (for accuracy comparison)\n",
    "t0 = time.time()\n",
    "xgb_prediction = model_xgb.predict(test_data)\n",
    "t1 = time.time()\n",
    "xgb_errors_count = np.count_nonzero(xgb_prediction - np.ravel(test_label))\n",
    "\n",
    "xgb_total = t1-t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### daal4py Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a prediction using daal4py for increased performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to daal4py\n",
    "daal_model = d4p.get_gbt_model_from_xgboost(model_xgb.get_booster())\n",
    "t0 = time.time()\n",
    "daal_prediction = d4p.gbt_classification_prediction(nClasses = n_classes).compute(test_data, daal_model)\n",
    "t1 = time.time()\n",
    "daal_errors_count = np.count_nonzero(np.ravel(daal_prediction.prediction) - test_label)\n",
    "\n",
    "d4p_total = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.absolute(xgb_errors_count - daal_errors_count) == 0\n",
    "y_test = np.ravel(test_label)\n",
    "daal_prediction = np.ravel(daal_prediction.prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy & Performance Comparison: XGBoots Prediction vs. Daal4py Prediction\n",
    "### No accuracy loss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nXGBoost prediction results (first 10 rows):\\n\", xgb_prediction[0:10])\n",
    "print(\"\\ndaal4py prediction results (first 10 rows):\\n\", daal_prediction[0:10])\n",
    "print(\"\\nGround truth (first 10 rows):\\n\", y_test[0:10])\n",
    "\n",
    "print(\"XGBoost errors count:\", xgb_errors_count)\n",
    "print(\"XGBoost accuracy score:\", 1 - xgb_errors_count / xgb_prediction.shape[0])\n",
    "\n",
    "print(\"\\ndaal4py errors count:\", daal_errors_count)\n",
    "print(\"daal4py accuracy score:\", 1 - daal_errors_count / daal_prediction.shape[0])\n",
    "\n",
    "print(\"\\n XGBoost Prediction Time:\", xgb_total)\n",
    "print(\"\\n daal4py Prediction Time:\", d4p_total)\n",
    "print(\"\\nAll looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = [1,2]\n",
    "pred_times = [xgb_total, d4p_total]\n",
    "tick_label = ['XGBoost Prediction', 'daal4py Prediction']\n",
    "plt.bar(left, pred_times, tick_label = tick_label, width = 0.5, color = ['red', 'blue'])\n",
    "plt.xlabel('Prediction Method'); plt.ylabel('time,s'); plt.title('Prediction time,s')\n",
    "plt.show()\n",
    "print(\"speedup:\",xgb_total/d4p_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = [1,2]\n",
    "xgb_acc = 1 - xgb_errors_count / xgb_prediction.shape[0]\n",
    "d4p_acc = 1 - daal_errors_count / daal_prediction.shape[0]\n",
    "pred_acc = [xgb_acc, d4p_acc]\n",
    "tick_label = ['XGBoost Prediction', 'daal4py Prediction']\n",
    "plt.bar(left, pred_acc, tick_label = tick_label, width = 0.5, color = ['red', 'blue'])\n",
    "plt.xlabel('Prediction Method'); plt.ylabel('accuracy, %'); plt.title('Prediction Accuracy, %')\n",
    "plt.show()\n",
    "print(\"Accuracy Difference\",xgb_acc-d4p_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[CODE_SAMPLE_COMPLETED_SUCCESFULLY]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oneAPI AIKit MLPackage",
   "language": "python",
   "name": "oneapi-aikit-mlpackage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
